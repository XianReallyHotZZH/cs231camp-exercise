{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[490, 491, 492, 493, 494, 495, 496, 497, 498, 499]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(490, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.351094\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** *Fill this in*\n",
    "因为是纯随机取的权重，所以计算得到的每一类别的得分因该是差不多的，接近1/N，这里就是0.1，所以损失就接近-log(0.1)了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -0.420111 analytic: -0.420111, relative error: 2.367118e-07\n",
      "numerical: 2.024311 analytic: 2.024311, relative error: 1.531624e-08\n",
      "numerical: 1.312643 analytic: 1.312643, relative error: 1.715999e-08\n",
      "numerical: -3.800574 analytic: -3.800574, relative error: 1.793554e-08\n",
      "numerical: -0.078609 analytic: -0.078610, relative error: 5.312431e-07\n",
      "numerical: -1.378337 analytic: -1.378337, relative error: 1.843476e-08\n",
      "numerical: -4.060030 analytic: -4.060030, relative error: 1.624987e-08\n",
      "numerical: 1.731711 analytic: 1.731711, relative error: 1.710850e-08\n",
      "numerical: 0.321094 analytic: 0.321094, relative error: 7.241980e-08\n",
      "numerical: -1.444224 analytic: -1.444224, relative error: 1.316633e-08\n",
      "numerical: -2.136807 analytic: -2.136807, relative error: 3.036717e-08\n",
      "numerical: -0.110185 analytic: -0.110185, relative error: 3.913380e-07\n",
      "numerical: -1.466379 analytic: -1.466379, relative error: 5.173448e-08\n",
      "numerical: 2.238883 analytic: 2.238883, relative error: 5.422978e-09\n",
      "numerical: 1.313494 analytic: 1.313494, relative error: 3.159934e-08\n",
      "numerical: -1.560880 analytic: -1.560880, relative error: 1.935893e-08\n",
      "numerical: -1.447789 analytic: -1.447789, relative error: 3.360469e-08\n",
      "numerical: -0.391041 analytic: -0.391041, relative error: 4.362100e-08\n",
      "numerical: 3.269104 analytic: 3.269104, relative error: 2.331197e-08\n",
      "numerical: -2.649616 analytic: -2.649616, relative error: 2.267788e-08\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "b = a * 2\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.351094e+00 computed in 0.211077s\n",
      "vectorized loss: 2.351094e+00 computed in 0.004750s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 780.207670\n",
      "iteration 100 / 1500: loss 286.572970\n",
      "iteration 200 / 1500: loss 106.245341\n",
      "iteration 300 / 1500: loss 40.225287\n",
      "iteration 400 / 1500: loss 16.071433\n",
      "iteration 500 / 1500: loss 7.196046\n",
      "iteration 600 / 1500: loss 3.947619\n",
      "iteration 700 / 1500: loss 2.738291\n",
      "iteration 800 / 1500: loss 2.351545\n",
      "iteration 900 / 1500: loss 2.201153\n",
      "iteration 1000 / 1500: loss 2.074831\n",
      "iteration 1100 / 1500: loss 2.073829\n",
      "iteration 1200 / 1500: loss 2.061672\n",
      "iteration 1300 / 1500: loss 2.086038\n",
      "iteration 1400 / 1500: loss 2.065855\n",
      "iteration 0 / 1500: loss 937.958563\n",
      "iteration 100 / 1500: loss 281.759876\n",
      "iteration 200 / 1500: loss 85.704917\n",
      "iteration 300 / 1500: loss 27.164106\n",
      "iteration 400 / 1500: loss 9.664716\n",
      "iteration 500 / 1500: loss 4.315317\n",
      "iteration 600 / 1500: loss 2.770361\n",
      "iteration 700 / 1500: loss 2.268615\n",
      "iteration 800 / 1500: loss 2.164212\n",
      "iteration 900 / 1500: loss 2.118185\n",
      "iteration 1000 / 1500: loss 2.199860\n",
      "iteration 1100 / 1500: loss 2.036433\n",
      "iteration 1200 / 1500: loss 2.151248\n",
      "iteration 1300 / 1500: loss 2.100060\n",
      "iteration 1400 / 1500: loss 2.079681\n",
      "iteration 0 / 1500: loss 1088.619160\n",
      "iteration 100 / 1500: loss 267.702236\n",
      "iteration 200 / 1500: loss 67.186434\n",
      "iteration 300 / 1500: loss 18.002610\n",
      "iteration 400 / 1500: loss 5.971094\n",
      "iteration 500 / 1500: loss 3.069410\n",
      "iteration 600 / 1500: loss 2.340327\n",
      "iteration 700 / 1500: loss 2.131727\n",
      "iteration 800 / 1500: loss 2.122694\n",
      "iteration 900 / 1500: loss 2.120821\n",
      "iteration 1000 / 1500: loss 2.129248\n",
      "iteration 1100 / 1500: loss 2.110679\n",
      "iteration 1200 / 1500: loss 2.146399\n",
      "iteration 1300 / 1500: loss 2.092519\n",
      "iteration 1400 / 1500: loss 2.129661\n",
      "iteration 0 / 1500: loss 1238.544158\n",
      "iteration 100 / 1500: loss 249.069880\n",
      "iteration 200 / 1500: loss 51.503153\n",
      "iteration 300 / 1500: loss 12.027925\n",
      "iteration 400 / 1500: loss 4.113197\n",
      "iteration 500 / 1500: loss 2.500589\n",
      "iteration 600 / 1500: loss 2.189361\n",
      "iteration 700 / 1500: loss 2.137696\n",
      "iteration 800 / 1500: loss 2.115262\n",
      "iteration 900 / 1500: loss 2.138358\n",
      "iteration 1000 / 1500: loss 2.120607\n",
      "iteration 1100 / 1500: loss 2.111043\n",
      "iteration 1200 / 1500: loss 2.110192\n",
      "iteration 1300 / 1500: loss 2.167351\n",
      "iteration 1400 / 1500: loss 2.121077\n",
      "iteration 0 / 1500: loss 1407.085922\n",
      "iteration 100 / 1500: loss 231.670413\n",
      "iteration 200 / 1500: loss 39.617818\n",
      "iteration 300 / 1500: loss 8.326628\n",
      "iteration 400 / 1500: loss 3.227394\n",
      "iteration 500 / 1500: loss 2.314362\n",
      "iteration 600 / 1500: loss 2.165427\n",
      "iteration 700 / 1500: loss 2.120113\n",
      "iteration 800 / 1500: loss 2.116886\n",
      "iteration 900 / 1500: loss 2.102131\n",
      "iteration 1000 / 1500: loss 2.119223\n",
      "iteration 1100 / 1500: loss 2.149127\n",
      "iteration 1200 / 1500: loss 2.166243\n",
      "iteration 1300 / 1500: loss 2.129235\n",
      "iteration 1400 / 1500: loss 2.124482\n",
      "iteration 0 / 1500: loss 778.497730\n",
      "iteration 100 / 1500: loss 105.524289\n",
      "iteration 200 / 1500: loss 15.802098\n",
      "iteration 300 / 1500: loss 3.972174\n",
      "iteration 400 / 1500: loss 2.325252\n",
      "iteration 500 / 1500: loss 2.105556\n",
      "iteration 600 / 1500: loss 2.100629\n",
      "iteration 700 / 1500: loss 2.073389\n",
      "iteration 800 / 1500: loss 2.104776\n",
      "iteration 900 / 1500: loss 2.123151\n",
      "iteration 1000 / 1500: loss 2.061880\n",
      "iteration 1100 / 1500: loss 2.050403\n",
      "iteration 1200 / 1500: loss 2.041002\n",
      "iteration 1300 / 1500: loss 2.179830\n",
      "iteration 1400 / 1500: loss 2.045094\n",
      "iteration 0 / 1500: loss 923.660613\n",
      "iteration 100 / 1500: loss 83.920052\n",
      "iteration 200 / 1500: loss 9.410784\n",
      "iteration 300 / 1500: loss 2.800912\n",
      "iteration 400 / 1500: loss 2.124016\n",
      "iteration 500 / 1500: loss 2.072528\n",
      "iteration 600 / 1500: loss 2.071740\n",
      "iteration 700 / 1500: loss 2.092985\n",
      "iteration 800 / 1500: loss 2.092591\n",
      "iteration 900 / 1500: loss 2.097509\n",
      "iteration 1000 / 1500: loss 2.072449\n",
      "iteration 1100 / 1500: loss 2.114924\n",
      "iteration 1200 / 1500: loss 2.083666\n",
      "iteration 1300 / 1500: loss 2.112097\n",
      "iteration 1400 / 1500: loss 2.138111\n",
      "iteration 0 / 1500: loss 1081.858013\n",
      "iteration 100 / 1500: loss 66.068200\n",
      "iteration 200 / 1500: loss 5.899014\n",
      "iteration 300 / 1500: loss 2.358538\n",
      "iteration 400 / 1500: loss 2.101694\n",
      "iteration 500 / 1500: loss 2.051686\n",
      "iteration 600 / 1500: loss 2.101369\n",
      "iteration 700 / 1500: loss 2.185894\n",
      "iteration 800 / 1500: loss 2.147929\n",
      "iteration 900 / 1500: loss 2.112989\n",
      "iteration 1000 / 1500: loss 2.062675\n",
      "iteration 1100 / 1500: loss 2.095514\n",
      "iteration 1200 / 1500: loss 2.138382\n",
      "iteration 1300 / 1500: loss 2.116759\n",
      "iteration 1400 / 1500: loss 2.081855\n",
      "iteration 0 / 1500: loss 1243.751119\n",
      "iteration 100 / 1500: loss 51.076241\n",
      "iteration 200 / 1500: loss 4.063635\n",
      "iteration 300 / 1500: loss 2.229222\n",
      "iteration 400 / 1500: loss 2.161488\n",
      "iteration 500 / 1500: loss 2.156138\n",
      "iteration 600 / 1500: loss 2.132118\n",
      "iteration 700 / 1500: loss 2.196561\n",
      "iteration 800 / 1500: loss 2.103047\n",
      "iteration 900 / 1500: loss 2.135307\n",
      "iteration 1000 / 1500: loss 2.137448\n",
      "iteration 1100 / 1500: loss 2.144336\n",
      "iteration 1200 / 1500: loss 2.048998\n",
      "iteration 1300 / 1500: loss 2.142984\n",
      "iteration 1400 / 1500: loss 2.118954\n",
      "iteration 0 / 1500: loss 1363.673489\n",
      "iteration 100 / 1500: loss 37.860648\n",
      "iteration 200 / 1500: loss 3.059507\n",
      "iteration 300 / 1500: loss 2.150509\n",
      "iteration 400 / 1500: loss 2.135556\n",
      "iteration 500 / 1500: loss 2.144522\n",
      "iteration 600 / 1500: loss 2.161756\n",
      "iteration 700 / 1500: loss 2.139926\n",
      "iteration 800 / 1500: loss 2.180410\n",
      "iteration 900 / 1500: loss 2.119527\n",
      "iteration 1000 / 1500: loss 2.098298\n",
      "iteration 1100 / 1500: loss 2.181786\n",
      "iteration 1200 / 1500: loss 2.140807\n",
      "iteration 1300 / 1500: loss 2.179500\n",
      "iteration 1400 / 1500: loss 2.136717\n",
      "iteration 0 / 1500: loss 770.517423\n",
      "iteration 100 / 1500: loss 39.056416\n",
      "iteration 200 / 1500: loss 3.808378\n",
      "iteration 300 / 1500: loss 2.164539\n",
      "iteration 400 / 1500: loss 2.110059\n",
      "iteration 500 / 1500: loss 2.122793\n",
      "iteration 600 / 1500: loss 2.104009\n",
      "iteration 700 / 1500: loss 2.088509\n",
      "iteration 800 / 1500: loss 2.168411\n",
      "iteration 900 / 1500: loss 2.066686\n",
      "iteration 1000 / 1500: loss 2.085733\n",
      "iteration 1100 / 1500: loss 2.097978\n",
      "iteration 1200 / 1500: loss 2.091207\n",
      "iteration 1300 / 1500: loss 2.073237\n",
      "iteration 1400 / 1500: loss 2.160682\n",
      "iteration 0 / 1500: loss 926.155904\n",
      "iteration 100 / 1500: loss 26.385023\n",
      "iteration 200 / 1500: loss 2.732861\n",
      "iteration 300 / 1500: loss 2.093625\n",
      "iteration 400 / 1500: loss 2.118858\n",
      "iteration 500 / 1500: loss 2.075773\n",
      "iteration 600 / 1500: loss 2.111699\n",
      "iteration 700 / 1500: loss 2.106212\n",
      "iteration 800 / 1500: loss 2.065920\n",
      "iteration 900 / 1500: loss 2.136811\n",
      "iteration 1000 / 1500: loss 2.103271\n",
      "iteration 1100 / 1500: loss 2.057094\n",
      "iteration 1200 / 1500: loss 2.152035\n",
      "iteration 1300 / 1500: loss 2.108836\n",
      "iteration 1400 / 1500: loss 2.138097\n",
      "iteration 0 / 1500: loss 1088.464794\n",
      "iteration 100 / 1500: loss 17.498626\n",
      "iteration 200 / 1500: loss 2.358445\n",
      "iteration 300 / 1500: loss 2.132943\n",
      "iteration 400 / 1500: loss 2.115228\n",
      "iteration 500 / 1500: loss 2.183289\n",
      "iteration 600 / 1500: loss 2.119723\n",
      "iteration 700 / 1500: loss 2.146231\n",
      "iteration 800 / 1500: loss 2.129606\n",
      "iteration 900 / 1500: loss 2.130799\n",
      "iteration 1000 / 1500: loss 2.131587\n",
      "iteration 1100 / 1500: loss 2.120865\n",
      "iteration 1200 / 1500: loss 2.099538\n",
      "iteration 1300 / 1500: loss 2.156984\n",
      "iteration 1400 / 1500: loss 2.090576\n",
      "iteration 0 / 1500: loss 1227.853830\n",
      "iteration 100 / 1500: loss 11.528378\n",
      "iteration 200 / 1500: loss 2.213150\n",
      "iteration 300 / 1500: loss 2.076521\n",
      "iteration 400 / 1500: loss 2.134803\n",
      "iteration 500 / 1500: loss 2.159735\n",
      "iteration 600 / 1500: loss 2.122935\n",
      "iteration 700 / 1500: loss 2.108997\n",
      "iteration 800 / 1500: loss 2.088240\n",
      "iteration 900 / 1500: loss 2.172900\n",
      "iteration 1000 / 1500: loss 2.126579\n",
      "iteration 1100 / 1500: loss 2.122100\n",
      "iteration 1200 / 1500: loss 2.137286\n",
      "iteration 1300 / 1500: loss 2.133976\n",
      "iteration 1400 / 1500: loss 2.121426\n",
      "iteration 0 / 1500: loss 1405.084508\n",
      "iteration 100 / 1500: loss 7.985407\n",
      "iteration 200 / 1500: loss 2.192960\n",
      "iteration 300 / 1500: loss 2.159357\n",
      "iteration 400 / 1500: loss 2.125241\n",
      "iteration 500 / 1500: loss 2.127885\n",
      "iteration 600 / 1500: loss 2.115093\n",
      "iteration 700 / 1500: loss 2.161325\n",
      "iteration 800 / 1500: loss 2.130203\n",
      "iteration 900 / 1500: loss 2.087168\n",
      "iteration 1000 / 1500: loss 2.129232\n",
      "iteration 1100 / 1500: loss 2.183940\n",
      "iteration 1200 / 1500: loss 2.157038\n",
      "iteration 1300 / 1500: loss 2.117228\n",
      "iteration 1400 / 1500: loss 2.148161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 770.119295\n",
      "iteration 100 / 1500: loss 15.555272\n",
      "iteration 200 / 1500: loss 2.311231\n",
      "iteration 300 / 1500: loss 2.064560\n",
      "iteration 400 / 1500: loss 2.092982\n",
      "iteration 500 / 1500: loss 2.068562\n",
      "iteration 600 / 1500: loss 2.118981\n",
      "iteration 700 / 1500: loss 2.093214\n",
      "iteration 800 / 1500: loss 2.121826\n",
      "iteration 900 / 1500: loss 2.092787\n",
      "iteration 1000 / 1500: loss 2.066434\n",
      "iteration 1100 / 1500: loss 2.023697\n",
      "iteration 1200 / 1500: loss 2.107957\n",
      "iteration 1300 / 1500: loss 2.112483\n",
      "iteration 1400 / 1500: loss 2.077348\n",
      "iteration 0 / 1500: loss 929.307841\n",
      "iteration 100 / 1500: loss 9.209789\n",
      "iteration 200 / 1500: loss 2.219584\n",
      "iteration 300 / 1500: loss 2.085951\n",
      "iteration 400 / 1500: loss 2.155972\n",
      "iteration 500 / 1500: loss 2.087164\n",
      "iteration 600 / 1500: loss 2.122877\n",
      "iteration 700 / 1500: loss 2.086988\n",
      "iteration 800 / 1500: loss 2.091610\n",
      "iteration 900 / 1500: loss 2.090187\n",
      "iteration 1000 / 1500: loss 2.136447\n",
      "iteration 1100 / 1500: loss 2.096904\n",
      "iteration 1200 / 1500: loss 2.115543\n",
      "iteration 1300 / 1500: loss 2.113022\n",
      "iteration 1400 / 1500: loss 2.163271\n",
      "iteration 0 / 1500: loss 1081.150370\n",
      "iteration 100 / 1500: loss 5.813484\n",
      "iteration 200 / 1500: loss 2.137856\n",
      "iteration 300 / 1500: loss 2.110145\n",
      "iteration 400 / 1500: loss 2.106479\n",
      "iteration 500 / 1500: loss 2.081419\n",
      "iteration 600 / 1500: loss 2.113763\n",
      "iteration 700 / 1500: loss 2.137511\n",
      "iteration 800 / 1500: loss 2.086194\n",
      "iteration 900 / 1500: loss 2.141200\n",
      "iteration 1000 / 1500: loss 2.106544\n",
      "iteration 1100 / 1500: loss 2.055999\n",
      "iteration 1200 / 1500: loss 2.158866\n",
      "iteration 1300 / 1500: loss 2.097907\n",
      "iteration 1400 / 1500: loss 2.151872\n",
      "iteration 0 / 1500: loss 1236.500421\n",
      "iteration 100 / 1500: loss 3.982700\n",
      "iteration 200 / 1500: loss 2.132265\n",
      "iteration 300 / 1500: loss 2.062499\n",
      "iteration 400 / 1500: loss 2.097949\n",
      "iteration 500 / 1500: loss 2.118101\n",
      "iteration 600 / 1500: loss 2.134825\n",
      "iteration 700 / 1500: loss 2.149418\n",
      "iteration 800 / 1500: loss 2.159336\n",
      "iteration 900 / 1500: loss 2.111244\n",
      "iteration 1000 / 1500: loss 2.174791\n",
      "iteration 1100 / 1500: loss 2.135277\n",
      "iteration 1200 / 1500: loss 2.115457\n",
      "iteration 1300 / 1500: loss 2.142976\n",
      "iteration 1400 / 1500: loss 2.151983\n",
      "iteration 0 / 1500: loss 1395.203221\n",
      "iteration 100 / 1500: loss 3.009259\n",
      "iteration 200 / 1500: loss 2.120955\n",
      "iteration 300 / 1500: loss 2.113964\n",
      "iteration 400 / 1500: loss 2.116505\n",
      "iteration 500 / 1500: loss 2.095326\n",
      "iteration 600 / 1500: loss 2.139358\n",
      "iteration 700 / 1500: loss 2.110655\n",
      "iteration 800 / 1500: loss 2.175331\n",
      "iteration 900 / 1500: loss 2.112363\n",
      "iteration 1000 / 1500: loss 2.124401\n",
      "iteration 1100 / 1500: loss 2.073564\n",
      "iteration 1200 / 1500: loss 2.097253\n",
      "iteration 1300 / 1500: loss 2.162133\n",
      "iteration 1400 / 1500: loss 2.127932\n",
      "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.328082 val accuracy: 0.347000\n",
      "lr 1.000000e-07 reg 3.000000e+04 train accuracy: 0.318673 val accuracy: 0.338000\n",
      "lr 1.000000e-07 reg 3.500000e+04 train accuracy: 0.310245 val accuracy: 0.331000\n",
      "lr 1.000000e-07 reg 4.000000e+04 train accuracy: 0.315776 val accuracy: 0.322000\n",
      "lr 1.000000e-07 reg 4.500000e+04 train accuracy: 0.309959 val accuracy: 0.325000\n",
      "lr 2.000000e-07 reg 2.500000e+04 train accuracy: 0.328714 val accuracy: 0.346000\n",
      "lr 2.000000e-07 reg 3.000000e+04 train accuracy: 0.328918 val accuracy: 0.350000\n",
      "lr 2.000000e-07 reg 3.500000e+04 train accuracy: 0.315633 val accuracy: 0.336000\n",
      "lr 2.000000e-07 reg 4.000000e+04 train accuracy: 0.309061 val accuracy: 0.324000\n",
      "lr 2.000000e-07 reg 4.500000e+04 train accuracy: 0.311367 val accuracy: 0.319000\n",
      "lr 3.000000e-07 reg 2.500000e+04 train accuracy: 0.324469 val accuracy: 0.339000\n",
      "lr 3.000000e-07 reg 3.000000e+04 train accuracy: 0.314592 val accuracy: 0.331000\n",
      "lr 3.000000e-07 reg 3.500000e+04 train accuracy: 0.304469 val accuracy: 0.323000\n",
      "lr 3.000000e-07 reg 4.000000e+04 train accuracy: 0.312776 val accuracy: 0.328000\n",
      "lr 3.000000e-07 reg 4.500000e+04 train accuracy: 0.305224 val accuracy: 0.323000\n",
      "lr 4.000000e-07 reg 2.500000e+04 train accuracy: 0.331184 val accuracy: 0.336000\n",
      "lr 4.000000e-07 reg 3.000000e+04 train accuracy: 0.314224 val accuracy: 0.324000\n",
      "lr 4.000000e-07 reg 3.500000e+04 train accuracy: 0.319857 val accuracy: 0.342000\n",
      "lr 4.000000e-07 reg 4.000000e+04 train accuracy: 0.299939 val accuracy: 0.319000\n",
      "lr 4.000000e-07 reg 4.500000e+04 train accuracy: 0.310898 val accuracy: 0.321000\n",
      "best validation accuracy achieved during cross-validation: 0.350000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "# Your code\n",
    "for lr_index in np.arange(learning_rates[0], learning_rates[1], 1e-7):\n",
    "    for reg_str_index in np.arange(regularization_strengths[0], regularization_strengths[1], 5e3):\n",
    "        soft_model = Softmax()\n",
    "        soft_model.train(X_train, y_train, learning_rate=lr_index, reg=reg_str_index,\n",
    "                      num_iters=1500, verbose=True)\n",
    "        train_acc = np.mean(y_train == soft_model.predict(X_train))\n",
    "        val_acc =  np.mean(y_val == soft_model.predict(X_val))\n",
    "        results[(lr_index, reg_str_index)] = [train_acc, val_acc]\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_softmax = soft_model\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.339000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inline Question** - *True or False*\n",
    "\n",
    "It's possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "*Your answer*:\n",
    "True\n",
    "\n",
    "*Your explanation*:\n",
    "对于SVM来说，只要新添加的数据点（样本），其对应的loss为0，那么对整体的loss是没有影响的，因为只要该样本的score根据折叶函数算出的loss为0即可。\n",
    "对于softmax来说，新添加的样本必然会计算出一个损失（即使分类正确并且得分很高），所以会在原本总体的loss上在加上一个该样本的loss，所以必然改变loss。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "num_test = np.arange(240).reshape((4,4,3,5))\n",
    "print(num_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  2,   7,  12],\n",
       "        [ 17,  22,  27],\n",
       "        [ 32,  37,  42],\n",
       "        [ 47,  52,  57]],\n",
       "\n",
       "       [[ 62,  67,  72],\n",
       "        [ 77,  82,  87],\n",
       "        [ 92,  97, 102],\n",
       "        [107, 112, 117]],\n",
       "\n",
       "       [[122, 127, 132],\n",
       "        [137, 142, 147],\n",
       "        [152, 157, 162],\n",
       "        [167, 172, 177]],\n",
       "\n",
       "       [[182, 187, 192],\n",
       "        [197, 202, 207],\n",
       "        [212, 217, 222],\n",
       "        [227, 232, 237]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test[:,:,:,2].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
